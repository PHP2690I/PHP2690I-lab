{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Lab 8: Local search algorithms",
   "id": "bb67f42c5a7db79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T00:15:11.041224Z",
     "start_time": "2025-03-12T00:15:11.037320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import random"
   ],
   "id": "bcad5d3ec796e8af",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Hill climbing\n",
    "\n",
    "Hill climbing is a mathematical optimization technique which belongs to the family of local search. It is an iterative algorithm that starts with an arbitrary solution to a problem, then attempts to find a better solution by incrementally changing a single element of the solution. If the change produces a better solution, an incremental change is made to the new solution, and so on until no further improvements can be found.\n",
    "\n",
    "One of the different part between hill climbing and gradient descent is that hill climbing does not require the gradient of the problem being optimized. This is a very great feature because it allows hill climbing to be used on problems that are not differentiable or have an unknown gradient, which means it is perfect for discrete optimization problems.\n",
    "\n",
    "Here is an example of a simple hill climbing algorithm:\n"
   ],
   "id": "ecd39e985daf6d51"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T23:53:05.582390Z",
     "start_time": "2025-03-11T23:53:05.576496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def objective(x):\n",
    "    return - (x - 3)**2 + 10\n",
    "\n",
    "def hill_climbing(start_x, step_size=0.1, max_iterations=500):\n",
    "    x = start_x\n",
    "    for _ in range(max_iterations):\n",
    "        candidate_x = x + np.random.choice([-step_size, step_size])\n",
    "        if objective(candidate_x) > objective(x):  \n",
    "            x = candidate_x\n",
    "    return x, objective(x)\n",
    "\n",
    "best_x, best_value = hill_climbing(start_x=np.random.uniform(0, 6))\n",
    "print(f\"Hill Climbing: Best x = {best_x:.4f}, Best Value = {best_value:.4f}\")"
   ],
   "id": "fb3790178220122c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hill Climbing: Best x = 3.0174, Best Value = 9.9997\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The n-queens problem is a classic problem in computer science. The problem is to place n queens on an nÃ—n chessboard so that no two queens threaten each other. Thus, a solution requires that no two queens share the same row, column, or diagonal.\n",
    "\n",
    "This is an example solution of 4-queens problem:\n",
    "\n",
    "![4-queens](https://media.geeksforgeeks.org/wp-content/uploads/20230814111654/Solution-Of-4-Queen-Problem.png)\n",
    "\n",
    "In the `fitness` function, we count the number of non-attacking pairs of queens. The optimal solution is when the fitness score is equal to `n * (n - 1) // 2`, which means no two queens threaten each other. The return value of the `fitness` function is higher when the solution is better. So the goal is to maximize the fitness score.\n",
    "\n",
    "In the `generate_neighbor` function, we generate a new board by moving one queen to a new row. The `hill_climbing` function is the main algorithm that solves the n-queens problem using hill climbing. It starts with a random initial state and generates a new board by moving one queen to a new row. If the new board has a better fitness score, the algorithm accepts the move. The algorithm stops when it reaches the optimal solution or the maximum number of iterations.\n"
   ],
   "id": "5844675afbfe3a30"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-12T00:06:18.393117Z",
     "start_time": "2025-03-12T00:06:18.379565Z"
    }
   },
   "source": [
    "def fitness(board):\n",
    "    \"\"\" Counts the number of non-attacking pairs of queens \"\"\"\n",
    "    n = len(board)\n",
    "    max_pairs = n * (n - 1) // 2  # Total possible non-attacking pairs\n",
    "    attacking_pairs = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if abs(board[i] - board[j]) == abs(i - j):  # Diagonal attack\n",
    "                attacking_pairs += 1\n",
    "\n",
    "    return max_pairs - attacking_pairs  # Higher is better\n",
    "\n",
    "def generate_neighbor(board, rng):\n",
    "    \"\"\" Generate a new board by swapping two queen positions (ensuring unique rows) \"\"\"\n",
    "    n = len(board)\n",
    "    new_board = board[:]\n",
    "    i, j = rng.choice(n, size=2, replace=False)  # Pick two different columns\n",
    "    new_board[i], new_board[j] = new_board[j], new_board[i]  # Swap their rows\n",
    "    return new_board\n",
    "\n",
    "def hill_climbing(n=8, max_iterations=1000, seed=42):\n",
    "    \"\"\" Solves the N-Queens problem using hill climbing with unique row constraints \"\"\"\n",
    "    rng = np.random.default_rng(seed)  # Fixed seed for reproducibility\n",
    "    board = rng.permutation(n)  # Start with a permutation (ensures unique row positions)\n",
    "    best_fitness = fitness(board)\n",
    "\n",
    "    for _ in range(max_iterations):\n",
    "        new_board = generate_neighbor(board, rng)\n",
    "        new_fitness = fitness(new_board)\n",
    "        if new_fitness > best_fitness:\n",
    "            board, best_fitness = new_board, new_fitness\n",
    "        if best_fitness == (n * (n - 1) // 2):\n",
    "            break\n",
    "\n",
    "    return board, best_fitness\n",
    "\n",
    "solution, best_fit = hill_climbing(n=8, seed=42)\n",
    "print(\"Final Board State (Row Positions of Queens):\", solution)\n",
    "print(\"Fitness Score:\", best_fit, \"(Higher is better)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Board State (Row Positions of Queens): [5 2 6 3 0 7 1 4]\n",
      "Fitness Score: 28 (Higher is better)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T00:06:59.883722Z",
     "start_time": "2025-03-12T00:06:59.879218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_chessboard(board):\n",
    "    n = len(board)\n",
    "    for row in range(n):\n",
    "        for col in range(n):\n",
    "            if board[col] == row:\n",
    "                print(\"Q\", end=\" \")\n",
    "            else:\n",
    "                print(\".\", end=\" \")\n",
    "        print()\n",
    "        \n",
    "print_chessboard(solution)"
   ],
   "id": "f6d765ea997417b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . Q . . . \n",
      ". . . . . . Q . \n",
      ". Q . . . . . . \n",
      ". . . Q . . . . \n",
      ". . . . . . . Q \n",
      "Q . . . . . . . \n",
      ". . Q . . . . . \n",
      ". . . . . Q . . \n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## K-Median Clustering\n",
    "\n",
    "K-Median Clustering is a clustering algorithm that aims to partition n data points into k clusters. The goal is to minimize the sum of distances between each data point and the median of its cluster. The median is the data point that minimizes the sum of distances to all other data points in the cluster.\n",
    "\n",
    "$$\n",
    "\\text{Cost} = \\sum_{i=1}^{n} \\min_{j=1}^{k} \\text{dist}(x_i, c_j)\n",
    "$$\n",
    "\n",
    "where $x_i$ is the data point, $c_j$ is the median of cluster $j$, and $\\text{dist}(x_i, c_j)$ is the distance between $x_i$ and $c_j$. The cost function is the sum of distances between each data point and the median of its cluster. The goal is to minimize this cost function.\n",
    "\n",
    "The `distance` function computes the Manhattan distance between two points. The `total_cost` function computes the total sum of distances from each point to its nearest median. The `generate_neighbor` function swaps one of the medians with a random non-median data point. The `k_median_local_search` function is the main algorithm that solves the k-median clustering problem using local search. It starts with k random medians and generates a new neighbor by swapping one of the medians with a random non-median data point. The algorithm stops when it reaches the optimal solution or the maximum number of iterations."
   ],
   "id": "d990971e890c5b12"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T00:43:21.009922Z",
     "start_time": "2025-03-12T00:43:20.921409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_points = np.array([\n",
    "    [2, 3], [5, 4], [3, 6], [8, 8], [1, 1],\n",
    "    [7, 5], [9, 9], [6, 2], [4, 7], [10, 6]\n",
    "])\n",
    "\n",
    "def distance(p1, p2):\n",
    "    \"\"\" Computes Manhattan distance between two points \"\"\"\n",
    "    return np.sum(np.abs(np.array(p1) - np.array(p2)))\n",
    "\n",
    "def total_cost(medians, data):\n",
    "    \"\"\" Computes total sum of distances from each point to its nearest median \"\"\"\n",
    "    return sum(min(distance(point, median) for median in medians) for point in data)\n",
    "\n",
    "def generate_neighbor(medians, data):\n",
    "    \"\"\" Swap one of the medians with a random non-median data point \"\"\"\n",
    "    new_medians = medians.copy()\n",
    "    swap_out = random.choice(medians)  # Pick a median to swap out\n",
    "    swap_in = random.choice([p for p in data if p.tolist() not in medians])  # Pick a new median\n",
    "    new_medians.remove(swap_out)\n",
    "    new_medians.append(tuple(swap_in))\n",
    "    return new_medians\n",
    "\n",
    "def k_median_local_search(data, k, max_iterations=1000, seed=42):\n",
    "    \"\"\" Local search for k-median clustering with proper integer conversion \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Start with k random medians\n",
    "    initial_medians = [tuple(map(int, p)) for p in random.sample(data.tolist(), k)]\n",
    "    best_medians = initial_medians\n",
    "    best_cost = total_cost(best_medians, data)\n",
    "    \n",
    "    for _ in range(max_iterations):\n",
    "        new_medians = generate_neighbor(best_medians, data)\n",
    "        new_medians = [tuple(map(int, m)) for m in new_medians]\n",
    "        new_cost = total_cost(new_medians, data)\n",
    "        \n",
    "        if new_cost < best_cost:\n",
    "            best_medians, best_cost = new_medians, new_cost\n",
    "    \n",
    "    return best_medians, best_cost\n",
    "\n",
    "optimal_medians, min_cost = k_median_local_search(data_points, k=3)\n",
    "print(\"Optimal Medians:\", optimal_medians)\n",
    "print(\"Minimum Cost:\", min_cost)"
   ],
   "id": "e328274c174992d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Medians: [(1, 1), (8, 8), (5, 4)]\n",
      "Minimum Cost: 23\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Genetic Algorithm\n",
    "\n",
    "Genetic Algorithm is a metaheuristic optimization algorithm inspired by the process of natural selection. It is based on the principles of genetics and natural selection. The algorithm starts with a random population of candidate solutions, then evolves the population over multiple generations. Each generation consists of selection, crossover, and mutation steps.\n",
    "\n",
    "1. Initialize Population: Start with a set of random k-medians.\n",
    "2. Evaluate Fitness: Compute the total clustering cost for each candidate.\n",
    "3. Selection: Pick better solutions (medians with lower cost).\n",
    "4. Crossover (Recombination): Combine solutions to create offspring.\n",
    "5. Mutation: Slightly change some solutions to maintain diversity.\n",
    "6. Repeat until convergence or a maximum number of generations.\n",
    "\n",
    "Here is an example implementation of the genetic algorithm for k-median clustering:"
   ],
   "id": "3b2b469d5694dcf4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T00:43:24.312567Z",
     "start_time": "2025-03-12T00:43:24.221321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def initialize_population(data, k, pop_size):\n",
    "    \"\"\"Creates an initial population of k-median solutions.\"\"\"\n",
    "    return [random.sample([tuple(p) for p in data.tolist()], k) for _ in range(pop_size)]\n",
    "\n",
    "def select_parents(population, data):\n",
    "    \"\"\"Selects the best individuals (lower cost) to be parents.\"\"\"\n",
    "    return sorted(population, key=lambda m: total_cost(m, data))[:len(population)//2]\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    \"\"\"Performs crossover by mixing medians from two parents.\"\"\"\n",
    "    crossover_point = len(parent1) // 2\n",
    "    child = parent1[:crossover_point] + parent2[crossover_point:]\n",
    "    return list(set(child))[:len(parent1)]  # Ensure k elements and no duplicates\n",
    "\n",
    "def mutate(solution, data, mutation_rate=0.1):\n",
    "    \"\"\"Randomly mutates a median by replacing one element.\"\"\"\n",
    "    if random.random() < mutation_rate:\n",
    "        replace_index = random.randint(0, len(solution) - 1)\n",
    "        new_median = tuple(random.choice(data.tolist()))\n",
    "        solution[replace_index] = new_median\n",
    "    return solution\n",
    "\n",
    "def genetic_algorithm_k_median(data, k, pop_size=10, generations=100, mutation_rate=0.1):\n",
    "    \"\"\"Genetic Algorithm for k-Median Optimization\"\"\"\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Initialize population\n",
    "    population = initialize_population(data, k, pop_size)\n",
    "\n",
    "    for _ in range(generations):\n",
    "        # Select best solutions as parents\n",
    "        parents = select_parents(population, data)\n",
    "\n",
    "        # Create next generation via crossover and mutation\n",
    "        offspring = []\n",
    "        while len(offspring) < pop_size:\n",
    "            p1, p2 = random.sample(parents, 2)\n",
    "            child = crossover(p1, p2)\n",
    "            mutated_child = mutate(child, data, mutation_rate)\n",
    "            offspring.append(mutated_child)\n",
    "\n",
    "        population = offspring  # Replace old generation\n",
    "\n",
    "    best_solution = min(population, key=lambda m: total_cost(m, data))\n",
    "    return best_solution, total_cost(best_solution, data)\n",
    "\n",
    "optimal_medians, min_cost = genetic_algorithm_k_median(data_points, k=3)\n",
    "print(\"Optimal Medians:\", optimal_medians)\n",
    "print(\"Minimum Cost:\", min_cost)"
   ],
   "id": "aaba9c1a73f92dd6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Medians: [(2, 3), (5, 4), (9, 9)]\n",
      "Minimum Cost: 23\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f3babb4107f4cdb9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
